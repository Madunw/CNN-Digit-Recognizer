{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJxz5ZNKqPeFYiWCfQXTl6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-LWnBtzr1n3",
        "outputId": "aca4252d-23ef-4e60-f2f1-e5a7be7b0fed"
      },
      "source": [
        "'''\n",
        "Trains a simple deep NN on the MNIST dataset.\n",
        "'''\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 2.2738 - accuracy: 0.1900 - val_loss: 2.2342 - val_accuracy: 0.2982\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 2.1940 - accuracy: 0.3737 - val_loss: 2.1443 - val_accuracy: 0.4611\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 2.0898 - accuracy: 0.5215 - val_loss: 2.0167 - val_accuracy: 0.5292\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.9353 - accuracy: 0.6008 - val_loss: 1.8270 - val_accuracy: 0.6567\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.7197 - accuracy: 0.6570 - val_loss: 1.5818 - val_accuracy: 0.7152\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.4711 - accuracy: 0.7052 - val_loss: 1.3352 - val_accuracy: 0.7140\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.2440 - accuracy: 0.7421 - val_loss: 1.1308 - val_accuracy: 0.7457\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0652 - accuracy: 0.7681 - val_loss: 0.9752 - val_accuracy: 0.7923\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.9317 - accuracy: 0.7900 - val_loss: 0.8616 - val_accuracy: 0.8067\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.8310 - accuracy: 0.8049 - val_loss: 0.7733 - val_accuracy: 0.8138\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.7539 - accuracy: 0.8182 - val_loss: 0.7046 - val_accuracy: 0.8288\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.6932 - accuracy: 0.8283 - val_loss: 0.6508 - val_accuracy: 0.8359\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.6448 - accuracy: 0.8361 - val_loss: 0.6078 - val_accuracy: 0.8462\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.6055 - accuracy: 0.8444 - val_loss: 0.5712 - val_accuracy: 0.8522\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.5731 - accuracy: 0.8505 - val_loss: 0.5428 - val_accuracy: 0.8583\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.5461 - accuracy: 0.8561 - val_loss: 0.5180 - val_accuracy: 0.8618\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.5232 - accuracy: 0.8612 - val_loss: 0.4972 - val_accuracy: 0.8668\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.5036 - accuracy: 0.8655 - val_loss: 0.4780 - val_accuracy: 0.8698\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.4865 - accuracy: 0.8695 - val_loss: 0.4627 - val_accuracy: 0.8749\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.4716 - accuracy: 0.8728 - val_loss: 0.4494 - val_accuracy: 0.8775\n",
            "Test loss: 0.4493686556816101\n",
            "Test accuracy: 0.8774999976158142\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}